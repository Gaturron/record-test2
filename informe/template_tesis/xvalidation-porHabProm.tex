% Juntar por cada hablante sus audios en una muestra sola promediando sus atributos
%\subsection{Promediando los atributos de cada hablante}
\subsection{Clasificación por hablante}
\label{prom_los_atributos_de_cada_hablante}

En este modelo de test variamos la instancia de clasificación. Para cada hablante juntamos sus grabaciones  calculando su promedio para cada atributo. La idea es juntar los atributos de un mismo hablante en una sola instancia. De esta forma, evitamos los atributos desconocidos en cada una de las grabaciones. 

En la tabla \ref{datos_orig} vemos un ejemplo de datos extraídos originalmente para entender mejor la idea. 

\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|ccccc|}
		\hline
		\multicolumn{2}{|l|}{Atributos} & A1 & A2 & A3 & ... & AN \\
		\hline 
		\textbf{Hablante 1} & \textbf{Audio1} & 1 & ? & 2 & & 2\\
		& \textbf{Audio2} & ? & ? & 1 & ... & ? \\
		& \textbf{Audio3} & 2 & ? & 3 & & ? \\
		\hline
		\textbf{Hablante 2} & \textbf{Audio1} & 1 & ? & ? & ... & ? \\
		& \textbf{Audio2} & 1 & 2 & ? & & ? \\
		\hline
	\end{tabular}
	\caption{Datos originales}
	\label{datos_orig}
\end{table}

Para cada hablante juntamos sus audios realizando el promedio de cada atributo. Por ejemplo: el Hablante 1 grabó 3 audios donde cada uno posee distintos atributos. Juntamos todos esos audios en uno promediando sus atributos: El Audio1 y Audio3 poseen el atributo A1 con valor 1 y 2 respectivamente. Entonces en la tabla \ref{PAH_datos_comb} tendremos Audio1 con A1 definido como el promedio de estos valores: $1 + 2 = 1,5$. 

Ninguno de los audios grabados originalmente por Hablante 1 definió A2, entonces en este caso no definimos ningún valor y va a quedar como valor desconocido. 

\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|ccccc|}
		\hline
		\multicolumn{2}{|l|}{Atributos} & A1 & A2 & A3 & ... & AN \\
		\hline 
		\textbf{Hablante 1} & \textbf{Audio1} & \textbf{1.5} & \textbf{?} & \textbf{1.667} & ... & \textbf{2}\\
		\hline
		\textbf{Hablante 2} & \textbf{Audio1} & \textbf{1} & \textbf{2} & \textbf{?} & ... & \textbf{?} \\
		\hline
	\end{tabular}
	\caption{Atributos modificados}
	\label{PAH_datos_comb}
\end{table}

Esta variante la realizamos solamente utilizando los atributos temporales. Descartamos los atributos acústicos porque corresponden a grabaciones que en muchas oportunidades sufren de ruido y pensamos que también podía ser una causa por la cual los clasificadores tienen mal rendimiento.

Resumiendo, por cada hablante se define una fila de atributos. Esto minimiza la cantidad de valores desconocidos por cada hablante.

\subsubsection*{Variando la cantidad de hablantes}

Además de esta modificación, realizaremos una variante más con respecto a la cantidad de hablantes de cada grupo. La primer variante será tener cantidad de hablantes aproximadamente pareja. La segunda variante será utilizando todo los hablantes.  

En la primer variante tomaremos 9 hablantes de Buenos Aires y de 8 Córdoba. Nunca es bueno descartar datos pero debemos tener un conjunto de datos equilibrado para saber si utilizando los atributos que definidos podemos realizar una mejor clasificación que el baseline. En la tabla \ref{PAH_esq_cv} vemos este esquema.

\begin{center}
	\mycirc[blue] Hablante para train \mycirc[red] Hablante para test
\end{center}

\begin{table}[H]
	\centering
	\begin{tabular}{cccccccccccc}
		& \multicolumn{11}{c}{\textit{Número de hablante}} \\
		& 1 & 2 & 3 & 4 & 5 & 6 & 7 & ... & 15 & 16 & 17 \\
		\hline \\
		Fold 1 &\mycirc[red] & \mycirc[blue] & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue] & ... & \mycirc[blue] & \mycirc[blue] & \mycirc[blue]  \\
		
		Fold 2 &\mycirc[blue] & \mycirc[red] & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue] & ... & \mycirc[blue] & \mycirc[blue] & \mycirc[blue]  \\
		
		Fold 3 &\mycirc[blue] & \mycirc[blue] & \mycirc[red]  & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue] & ... & \mycirc[blue] & \mycirc[blue] & \mycirc[blue]  \\
		
		\multicolumn{11}{c}{\textit{...}}	\\
		
		Fold 17 &\mycirc[blue] & \mycirc[blue] & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue]  & \mycirc[blue] & ... & \mycirc[blue] & \mycirc[blue] & \mycirc[red]   \\
		
	\end{tabular}
	\caption{Esquema de validación cruzada}
	\label{PAH_esq_cv}
\end{table}

Agregamos un hablante más de Buenos Aires ya que, de esta manera, entrenamos ZeroRule con instancias equilibradas. 

Con este esquema, cuando quitamos un hablante para testeo, el algoritmo ZeroRule entrenará la mitad de las veces con instancias equilibradas en el conjunto de entrenamiento. De esta forma, este clasificador clasificará correctamente la mitad de las veces.

Si utilizáramos igual cantidad de hablantes en ambos grupos, sucedería lo siguiente: al principio  descartaríamos un hablante para testear. El clasificador ZeroRule entrenaría en el conjunto de hablantes y elegiría siempre la clase del hablante que no fue descartada para testeo, ya que es la clase mayoritaria. Cuando intente clasificar el hablante de testeo no dará correcto. Esto se repite en todos los folds haciendo que su performance sea $0\%$.

Este cambio es menor y nos ayuda a que el análisis sea más correcto. Entonces el conjunto de datos posee sólo una unidad de diferencia entre ambos grupos. La elección de cada uno de estos hablantes fue al azar. Como el esquema anterior, tendremos un fold por cada hablante. 

En la segunda variante no descartaremos datos. Realizaremos el mismo procedimiento teniendo en cuenta los 27 hablantes obtenidos.

\subsubsection{Resultados}

Los resultados de este cross-validaton podemos observarlos en la tabla \ref{HPTDT_clas_xval_porHab} para la variante utilizando hablantes equilibrados, y en la tabla \ref{HPTDT_clas_xval_porHab_sindescartar} para todos los hablantes.

{\small 	
	\begin{table}[H]
		\centering
		\begin{tabular}{|l|c|c|c|c|c|c|}
			\hline
			\textbf{}  & \textbf{Zero Rule} & \textbf{Ripper} & \textbf{C4.5} & \textbf{SVM} & \textbf{NaiveBayes} \\ \hline
			\textbf{Promedio} & 53  & 53 & 76 & 94 & 76 \\ \hline
		\end{tabular}
		\caption{Clasificación correcta en porcentaje promediando los atributos por hablante de los 17 hablantes (utilizando 9 de Buenos Aires, 8 Córdoba)}
		\label{HPTDT_clas_xval_porHab}
	\end{table}
}

{\small 	
	\begin{table}[H]
		\centering
		\begin{tabular}{|l|c|c|c|c|c|c|}
			\hline
			\textbf{}  & \textbf{Zero Rule} & \textbf{Ripper} & \textbf{C4.5} & \textbf{SVM} & \textbf{NaiveBayes} \\ \hline
			\textbf{Promedio} & 70  & 77 & 70 & 96 & 88 \\ \hline
		\end{tabular}
		\caption{Clasificación correcta en porcentaje promediando los atributos por hablante \textbf{sin descartar datos} (utilizando los 27 hablantes)}
		\label{HPTDT_clas_xval_porHab_sindescartar}
	\end{table}
}

%viejo y mal
%\begin{table}[H]
%	\centering
%	\begin{tabular}{|l|c|c|c|c|c|c|}
%		\hline
%		\textbf{}  & \textbf{Zero Rule} & \textbf{Ripper} & \textbf{C4.5} & \textbf{SVM} & \textbf{NaiveBayes} \\ \hline
%		\textbf{Promedio} & 53.33 & 60 & 60 & \textbf{93.33} & 80  \\ \hline
%	\end{tabular}
%	\caption{Clasificación correcta en porcentaje}
%	\label{PAH_class_corr_en_pct}
%\end{table}

Podemos observar que el clasificador ZeroRule estuvo más cerca de un valor esperable para el tipo de clasificador que es. Todos los demás dieron por arriba de este valor. Se destacaron los dos clasificadores que utilizan todos los atributos ponderados: Support vector machine y NaiveBayes.

Los resultados sobre el p-valor de cada test estadístico de Wilcoxon y Test t de Student se puede ver en la tabla \ref{PAH_res_tests_wilcoxon_student}.

\begin{table}[H]
	\centering
	\footnotesize 
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{ }  & \multicolumn{2}{c|}{Hablantes equilibrados } & \multicolumn{2}{|c|}{Todos los hablantes} \\ \cline{2-5}
		& \textbf{Student Test} & \textbf{Wilcoxon Test} & \textbf{Student Test} & \textbf{Wilcoxon Test} \\ \hline		
			\textbf{ZeroR y Ripper} & 0.5 & 0.5229 & 0.2123 & 0.242 \\ \hline
			\textbf{ZeroR y C4.5} & 0.08174 & 0.09083 & 0.5 & 0.5793 \\ \hline
			\textbf{ZeroR y NaiveBayes} & 0.05186 & 0.06472 & 0.02855 & 0.0363 \\ \hline
			\textbf{ZeroR y SVM} & \textbf{0.002048} & \textbf{0.005367} & \textbf{0.002826} & \textbf{0.005367} \\ \hline
	\end{tabular}
	\caption{Resultados de cada test representado en p-valor}
	\label{PAH_res_tests_wilcoxon_student}
\end{table}

Los clasificadores pasaron el test Shapiro-Wilk, entonces podemos afirmar que los resultados de cada clasificador corresponden a una distribución Normal y realizar el test t de Student.

Podemos observar que para el clasificador Support vector machine posee p-valor menor a 0,05 en ambas variantes. Esto quiere decir que para \textbf{Support vector machine hay evidencia suficiente de ser mejor que el baseline}. Por otro lado, los demás no pudieron lograr este cometido. 

\subsubsection{Análisis de los clasificadores construidos}

Analizando los clasificadores notamos que el clasificador C4.5 armó árboles de decisión más elaborados. Notamos eso también viendo que su performance superó a Zero Rules. 

Veamos un árbol de decisión generado por C4.5. Este corresponde al fold 7. 

\dirtree{%
	.1 root.
	.2 $FON\_vowel\_norm <= 7.221824$.
	.3 $FON\_ll\_norm <= -24.007: cba (2.33/0.22)$.
	.3 $FON\_ll\_norm > -24.007: bsas (18.67/0.89)$.
	.2 $FON\_vowel\_norm > 7.221824: cba (5.0)$.
}
Los árboles de decisión generados esta vez utilizan mucho  atributos como $FON\_ll\_norm$ y $FON\_vowel\_norm$ en varios folds. Los demás clasificadores también armaron sus reglas: SVM y NaiveBayes ponderaron cada atributo para su clasificación mientras que Ripper armó sus reglas parecidas a C4.5. 

\subsubsection{Características del modelo de test}

Este modelo de test dio muy buenos resultados. El clasificador ZeroR tuvo una performance esperada de alrededor del 50 \% mientras que el clasificador C4.5 pudo armar árboles mejores. 

Sin embargo, la forma que evitamos los valores desconocidos no es la mejor. El resultado de un fold para un determinado clasificador es 0\% o 100\%. Esto sucede porque es sólo una instancia la que representa. 

Esto también se ve reflejado en las matrices de confusión de cada fold. Podemos ver en la tabla \ref{PAH_mat_conf_f1_solo0o1} la matriz de confusión del clasificador Ripper para el fold 1. En cada una de ellas, para cualquier clasificador, siempre se encuentra una sola instancia. 

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		Buenos Aires & Córdoba & \\ \hline
		1 & 0 & Buenos Aires\\ \hline
		0 & 0 & Córdoba\\ \hline
	\end{tabular}
	\caption{Matriz de confusión fold 1}
	\label{PAH_mat_conf_f1_solo0o1}
\end{table}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% Correcciones a agregar
%Correcciones a agregar
%
%	Promediando los atributos por hablante \textbf{sin descartar datos} (utilizando los 27 hablantes)
%	
%	{\small 	
%		\begin{table}[H]
%			\centering
%			\begin{tabular}{|l|c|c|c|c|c|c|}
%				\hline
%				\textbf{}  & \textbf{Zero Rule} & \textbf{Ripper} & \textbf{C4.5} & \textbf{SVM} & \textbf{NaiveBayes} \\ \hline
%				\textbf{Promedio} & 70  & 77 & 70 & 96 & 88 \\ \hline
%			\end{tabular}
%			\caption{Clasificación correcta en porcentaje}
%			\label{HPTDT_clas_xval_porHab}
%		\end{table}
%	}
%	
%	Promediando los atributos por hablante de los 17 hablantes
%	(utilizando 9 de Buenos Aires, 8 Córdoba)
%	
%	{\small 	
%		\begin{table}[H]
%			\centering
%			\begin{tabular}{|l|c|c|c|c|c|c|}
%				\hline
%				\textbf{}  & \textbf{Zero Rule} & \textbf{Ripper} & \textbf{C4.5} & \textbf{SVM} & \textbf{NaiveBayes} \\ \hline
%				\textbf{Promedio} & 53  & 53 & 76 & 94 & 76 \\ \hline
%			\end{tabular}
%			\caption{Clasificación correcta en porcentaje}
%			\label{HPTDT_clas_xval_porHab}
%		\end{table}
%	}
%
