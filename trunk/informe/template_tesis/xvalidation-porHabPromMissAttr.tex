% Cada hablante que tenga un atributo '?' cambiarlo por el promedio de ese atributo en las demás audios
\subsection{Promediando los atributos de cada hablante para valores desconocidos}
\label{prom_los_atributos_de_cada_hablante_para_valores_desconocidos}

En el anterior esquema vimos que promediando los atributo evitamos tener valores desconocidos. Sí bien esto es cierto, no es necesario promediar en todos los casos. 

Supongamos que tenemos el mismo conjunto de datos a la tabla \ref{datos_orig}. Si para cada hablante promediamos sus atributos estaríamos perdiendo información. El hablante 1 tiene en el Audio1 el atributo A1 definido como 1, mientras que en el Audio3 como 2. Si realizáramos el promedio, estos valores específicos para estos audios los perderíamos.

%\begin{table}[H]
%	\centering
%	\begin{tabular}{|l|l|ccccc|}
%		\hline
%		\multicolumn{2}{|l|}{Atributos} & A1 & A2 & A3 & ... & AN \\
%		\hline 
%		\textbf{Hablante 1} & \textbf{Audio1} & 1 & ? & 2 & & 2\\
%		& \textbf{Audio2} & ? & ? & 1 & ... & ? \\
%		& \textbf{Audio3} & 2 & ? & 3 & & ? \\
%		\hline
%		\textbf{Hablante 2} & \textbf{Audio1} & 1 & ? & ? & ... & ? \\
%		& \textbf{Audio2} & 1 & 2 & ? & & ? \\
%		\hline
%	\end{tabular}
%	\caption{Atributos original}
%	\label{attr_orig}
%\end{table}

Es por ello que proponemos esta variante. Cuando haya un atributo desconocido en un audio, definiremos su valor promediando con los atributos de los demás audios del mismo hablante. En la tabla \ref{PAHD_attr_mod} se puede ver el resultado de esta variante marcado con negrita los nuevos valores. 

Por ejemplo: para el Hablante 1, el Audio1 no tiene definido el atributo A1. Entonces definimos su valor promediando ese atributo utilizando los demás audios. El Audio1 y Audio3 sí tienen este atributo definido y sus valores son 2 y 1 respectivamente. Realizamos el promedio nuevamente: $ 2 + 1 / 2 = 1,5$ entonces el valor del atributo 1 para el Audio2 es 1,5. De esta forma, no perdemos información con respecto al audio extraído.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|ccccc|}
		\hline
		\multicolumn{2}{|l|}{Atributos} & A1 & A2 & A3 & ... & AN \\
		\hline 
		\textbf{Hablante 1} & \textbf{Audio1} & 1 & ? & 2 & & 2\\
		& \textbf{Audio2} & \textbf{1.5} & ? & 1 & ... & \textbf{2} \\
		& \textbf{Audio3} & 2 & ? & 3 & & \textbf{2} \\
		\hline
		\textbf{Hablante 2} & \textbf{Audio1} & 1 & \textbf{2} & ? & ... & ? \\
		& \textbf{Audio2} & 1 & 2 & ? & & ? \\
		\hline
	\end{tabular}
	\caption{Atributos modificados 2}
	\label{PAHD_attr_mod}
\end{table}

\subsubsection{Resultados}

Podemos observar los resultados del promedio de los folds para cada clasificador en la tabla \ref{PAHD_class_corr_en_pct}. En este caso, el clasificador Zero Rule tuvo el porcentaje esperado y los demás por arriba de su valor. Esto nos muestra que utilizando estos atributos se puede superar el baseline. El clasificador que mejor performance tuvo fue Support vector machine.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|c|c|c|c|c|c|}
		\hline
		\textbf{}  & \textbf{Zero Rule} & \textbf{Ripper} & \textbf{C4.5} & \textbf{SVM} & \textbf{NaiveBayes} \\ \hline
		\textbf{Promedio} & 50 & 72.44 & 73.48 & \textbf{77.19} & 74.62 \\ \hline
	\end{tabular}
	\caption{Clasificación correcta en porcentaje}
	\label{PAHD_class_corr_en_pct}
\end{table}

Los clasificadores pasaron el test Shapiro-Wilk. Gracias a esto podemos afirmar que los resultados de cada clasificador corresponden a una distribución Normal y podemos realizar el test de Student para todos ellos.

Corrimos los test estadísticos Wilcoxon y Test t de Student y obtuvimos que los resultados cada fold de NaiveBayes y Support vector machine tienen evidencia estadística para ser mejor que Zero rules. Podemos ver los p-valores en la tabla \ref{PAHD_res_tests_wilcoxon_student}. Recordemos que para que tenga evidencia suficiente su p-valor debe ser menor a 0,05.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|c|c|c|c|c|c|}
		\hline
		\textbf{}  & \textbf{Student Test} & \textbf{Wilcoxon Test} \\ \hline
		\textbf{ZeroR y Ripper}  & 0.06537 & 0.1284 \\ \hline
		\textbf{ZeroR y C4.5}  & 0.06156 &  0.1111 \\ \hline
		\textbf{ZeroR y NaiveBayes}  & \textbf{0.03916} & 0.06111 \\ \hline
		\textbf{ZeroR y SVM}  &  \textbf{0.02936} & \textbf{0.03522} \\ \hline
	\end{tabular}
	\caption{Resultados de cada test representado en p-valor}
	\label{PAHD_res_tests_wilcoxon_student}
\end{table}

\subsubsection{Análisis de los clasificadores construidos}

Analizando los clasificadores para cada fold notamos que todos armaron clasificadores utilizando los atributos definidos. Como el modelo de test anterior, Support vector machine y NaiveBayes utilizaron todos los atributos mientras C4.5 y Ripper utilizaron reglas más simples.

\subsubsection{Características del modelo de test}

Con esta esquema mejoramos las matrices de confusión. La tabla \ref{PAHD_mat_conf_f1} corresponde al primer fold. Notamos que ahora sí se analiza cada audio y se intenta clasificarlo. 

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		Buenos Aires & Córdoba & \\ \hline
		33 & 1 & Buenos Aires\\ \hline
		0 & 0 & Córdoba\\ \hline
	\end{tabular}
	\caption{Matriz de confusión fold 1}
	\label{PAHD_mat_conf_f1}
\end{table}
